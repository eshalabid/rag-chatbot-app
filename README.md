# ğŸ¤– RAG Chatbot Application

This is a lightweight Retrieval-Augmented Generation (RAG) chatbot application that combines **semantic search** with **LLM-based answer generation**, using:

- âš¡ **FastAPI** for backend APIs  
- ğŸ“¦ **pgvector** with PostgreSQL to store dense vector embeddings  
- ğŸ§  **MiniLM (all-MiniLM-L6-v2)** for embedding generation  
- ğŸ’¬ **TinyLlama** or **Azure GPT-4o-mini** for response generation  
- ğŸŒ **Streamlit** for a simple and interactive frontend  
- ğŸ§© Modular **LangChain-style tools** for greetings, math, and web lookup  

---

## ğŸš€ Features

- ğŸ” **Semantic Search** using pgvector + MiniLM embeddings  
- ğŸ§  **RAG Pipeline** retrieves relevant content and sends it to an LLM  
- ğŸ§® **Built-in Tools** for greeting, math (BODMAS), and simple web search  
- ğŸŒ **Streamlit UI** for real-time querying  
- ğŸ”— **FastAPI Backend** with clean routing  
- ğŸ§  **LangChain Agent** integrates tools and context-aware LLM responses  
- ğŸ” Fully local setup (with optional Azure OpenAI support)  

---

## ğŸ—‚ï¸ Project Structure

.
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ main.py # FastAPI app entry point
â”‚ â”œâ”€â”€ view.py # API route definitions
â”‚ â”œâ”€â”€ stream.py # Streamlit frontend
â”‚
â”œâ”€â”€ tools/
â”‚ â”œâ”€â”€ greeting_tool.py # Simple greeting handler
â”‚ â”œâ”€â”€ bodmas_tool.py # Math solver (BODMAS)
â”‚ â””â”€â”€ web_search_tool.py # Web link tool (GitHub, YouTube, etc.)
â”‚
â”œâ”€â”€ agent.py # LangChain agent setup
â”œâ”€â”€ llm_provider.py # Azure OpenAI or TinyLlama model setup
â”œâ”€â”€ table.py # Ingests CSV and stores vector embeddings
â”œâ”€â”€ similarity_search.py # Performs pgvector-based search
â”œâ”€â”€ README.md # You're reading this :)
â”œâ”€â”€ LICENSE # Project license
â”œâ”€â”€ .env # ğŸ” API keys and secrets (not tracked)
â””â”€â”€ .gitignore # Ignores .env, pycache, etc.



---

## âš™ï¸ How to Run

1ï¸âƒ£ Install Requirements: 
pip install -r requirements.txt

2ï¸âƒ£ Start PostgreSQL with pgvector extension
Make sure your PostgreSQL DB has the vector extension installed:
CREATE EXTENSION IF NOT EXISTS vector;

3ï¸âƒ£ Populate the Vector Database
Update the CSV path in table.py, then run:
python table.py

4ï¸âƒ£ Run the FastAPI Backend
uvicorn backend.main:app --reload

5ï¸âƒ£ Launch the Streamlit Frontend
streamlit run backend/stream.py

ğŸ“¦ Requirements
Python 3.10+

fastapi

streamlit

psycopg2

pgvector

sentence-transformers

torch

langchain

requests

openai (or Azure SDK for GPT-4o-mini)

ğŸ“Œ Notes
Embeddings use: sentence-transformers/all-MiniLM-L6-v2

LLM via: Azure GPT-4o-mini (replaceable with local TinyLlama or any other)

Proxy variables were removed for clean, universal use

Easily extensible with more tools or file types

ğŸ” Environment Setup
Create a .env file in the project root with your keys:
AZURE_API_KEY=your_azure_openai_key